# -*- coding: utf-8 -*-
"""train + test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MrUqT4kaVWamTBAklEP9IxMlsXp9WVWw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.utils import plot_model

import torch
import torch.nn as nn
from torch.autograd import Variable

import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from torch.utils.data import random_split
from sklearn.metrics import confusion_matrix

torch.__version__

if torch.cuda.is_available():    
    device = torch.device("cuda")
    print('There are %d GPU(s) available.' % torch.cuda.device_count())
    print('We will use the GPU:', torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print('No GPU available, using the CPU instead.')

# Load fashion-MNIST dataset
train_dataset = torchvision.datasets.FashionMNIST(root='./datasets',
                                        train=True,
                                        transform=transforms.ToTensor(),
                                        download=True)
 
test_dataset = torchvision.datasets.FashionMNIST(root='./datasets',
                                        train=False,
                                        transform=transforms.ToTensor(),
                                        download=True)

len(train_dataset)

# Train dataset 을 download 후, train dataset, valid dataset 으로 split 하여 사용

train_size = 40000
val_size = len(train_dataset) - train_size
train_dataset, valid_dataset = random_split(train_dataset, [train_size, val_size])

print("train: ", len(train_dataset))
print("valid: ", len(valid_dataset))
print("test : ", len(test_dataset))

# Hyper parameters
sequence_length = 28
input_size = 28
hidden_size = 128
num_layers = 5
num_classes = 10
batch_size = 50
num_epochs = 10
learning_rate = 0.001

# create data loaders 
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle = True)
validation_loader = torch.utils.data.DataLoader(valid_dataset, batch_size*2)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle = False)

# cf) Check dataloader shape
image, label = next(iter(validation_loader))
print(image.size()) # [Batch, Channel, Height, Width]

# 데이터셋 을 다운받은 후 image 한 장의 shape 확인 + 위와 같이 데이터셋에 포함된 image를 plt로 plot 해보기

CLASSES = {
    0: 'T-shirt/top',
    1: 'Trouser',
    2: 'Pullover',
    3: 'Dress',
    4: 'Coat',
    5: 'Sandal',
    6: 'Shirt',
    7: 'Sneaker',
    8: 'Bag',
    9: 'Ankle boot'
}

# Display image and label.
train_features, train_labels = next(iter(train_loader))
print(f"Feature batch shape: {train_features.size()}")
print(f"Labels batch shape: {train_labels.size()}")
img = train_features[0].squeeze()
label = train_labels[0]

plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {label}")

class RNN(nn.Module):
  def __init__(self, intput_size, hidden_size, num_layers, num_classes):
    super(RNN, self).__init__()
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
    self.fc = nn.Linear(hidden_size, num_classes)

  def forward(self, x):
    # set initial hidden states and cell states
    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # torch.size([2, 50, 128])
    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # torch.size([2, 50, 128])

    #Forward propagate LSTM
    out, _  = self.lstm(x, (h0, c0)) # output: tensor [batch_size, seq_length, hidden_size]

    #Decode the hidden state of the last time step
    out = self.fc(out[:,-1,:])

    return out

model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)
model.cuda()
print(model)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# 매 epoch 마다 valid dataset 에 대한 성능 (loss / accuracy) 를 측정

####### Train #######
count = 0
loss_list = []
iteration_list = []
accuracy_list = []

total_step = len(validation_loader)

for epoch in range(num_epochs):
  for i, (image, label) in enumerate(validation_loader):
    image = image.reshape(-1, sequence_length, input_size).to(device)
    label = label.to(device)

    # Forward
    output = model(image)
    loss = criterion(output, label)

    # Backward and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    count += 1

    with torch.no_grad():
      correct = 0

      for image, label in test_loader:
        image = image.reshape(-1, sequence_length, input_size).to(device)
        label = label.to(device)
        output = model(image)
        _, pred = torch.max(output.data, 1)
        correct += (pred == label).sum().item()
        accuracy = 100 * correct / len(test_dataset)
        loss_list.append(loss.data)
        iteration_list.append(count)
        accuracy_list.append(accuracy)

    if count % 200 == 0: 
      print("Epoch [{}/{}], Step[{}/{}], Loss:{:.4f}, Accuracy:{:.4f}".format(epoch+1, num_epochs, 
                                                                              count, total_step, 
                                                                              loss.item(), accuracy))

plt.plot(iteration_list, loss_list)
plt.xlabel("Iteration")
plt.ylabel("Loss")
plt.title("Iterations vs Loss")
plt.show()

plt.plot(iteration_list, accuracy_list)
plt.xlabel("Iteration")
plt.ylabel("Accuracy")
plt.title("Iterations vs Accuracy")
plt.show()

torch.save(model.state_dict(), 'rnn_20180305.pth')

!ls

model2 = torch.load('rnn_20180305.pth')
