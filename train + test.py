# -*- coding: utf-8 -*-
"""train + test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hzzyy1_XS7ys8QyW2JgkLnl28wy0vAav
"""

# import all necessary libraries

import torch
import torchvision
import torchvision.transforms as transforms
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from keras.callbacks import EarlyStopping
from tensorflow.keras.datasets.cifar10 import load_data
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D

# load cifar10 datasets
# check the shape of x_train and x_test

cifar10 = tf.keras.datasets.cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

train_data = x_train.reshape(x_train.shape[0], 32, 32 ,3)
test_data = x_test.reshape(x_test.shape[0], 32, 32 ,3)

INPUT_SHAPE = (32,32,3)

model = tf.keras.models.Sequential()

# 1st layer
# 5x5kernel,6channelout,Batchnormalization 
# Activation:ReLU
# Max-pooling(2x2kernel,2stride)

model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation = 'relu',
                                 padding = 'valid', input_shape = INPUT_SHAPE))
model.add(BatchNormalization())
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1)))

# 2nd layer
# 3x3kernel,16channelout,Batchnormalization 
# Activation=ReLU
# Max-pooling(2x2kernel,2stride)

model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation = 'relu',
                                 padding = 'valid', input_shape = INPUT_SHAPE))
model.add(BatchNormalization())
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1)))

# 3rd layer
# 3x3kernel,32channelout,Batchnormalization 
# Activation=ReLU
# Max-pooling(2x2kernel,2stride)

model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation = 'relu',
                                 padding = 'valid', input_shape = INPUT_SHAPE))
model.add(BatchNormalization())
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1)))

model.add(tf.keras.layers.Flatten())

# 4th layer
# DenseLayerwith120output 
# Activation:ReLU

model.add(tf.keras.layers.Dense(120, activation='relu'))

# 5th layer
# DenseLayerwith84output 
# Activation:ReLU

model.add(tf.keras.layers.Dense(84, activation='relu'))
model.add(tf.keras.layers.Dropout(rate=0.3))

# Out-layer
# DenseLayer

model.add(tf.keras.layers.Dense(10, activation='softmax'))

opt = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])
model.summary()

history = model.fit(x_train, y_train,batch_size=100, epochs=20, 
                    validation_split=0.2,verbose=1)
print(history.history)

plt.plot(history.history['accuracy'])
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

plt.plot(history.history['loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

torch.save(model.save, 'my_model.pth')
model.save('model1')

loaded_model = tf.keras.models.load_model('model1')
loaded_model.summary()

loss, acc = loaded_model.evaluate(x_test, y_test, verbose=2)
print('Loss: ', loss)
print('Acc: ', acc)